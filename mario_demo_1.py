# ===============================
# MVP é­”æ³•é¡ç‰† - å®Œæ•´ PDF ä¸‹è¼‰ç‰ˆ (æ•´åˆæ’ç‰ˆå»ºè­°)
# ===============================


import streamlit as st
import pandas as pd
import plotly.express as px
from collections import Counter
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from fpdf import FPDF
import os
import time
import tempfile

    
# --------------------------


st.set_page_config(page_title="ğŸ•¹ï¸ Mario äº’å‹•é­”æ³•é¡", layout="wide")
st.title("ğŸ•¹ï¸ Mario äº’å‹•é­”æ³•é¡ â€” æ—…éŠè©•è«–å„€è¡¨æ¿")
st.write(
    "æ­¡è¿ä¾†åˆ° Mario äº’å‹•é­”æ³•é¡ï¼Œé€™è£¡ä»¥å°¼æ³Šçˆ¾æ—…éŠæ™¯é»åŸå§‹è©•è«–è³‡æ–™ç¶“éæ•¸æ“šæ¢å‹˜ã€è¦–è¦ºåŒ–è™•ç†å¾Œçš„åœ–åƒä½œç‚º Demo ç¤ºç¯„ï¼Œ"
    "è«‹é€éå´é‚Šæ¬„é¸æ“‡æ™¯é»ï¼Œå³æ™‚çœ‹åˆ°æƒ…ç·’åœ°åœ–åˆ†å¸ƒèˆ‡é—œéµå­—ã€‚è³‡æ–™ä¾†æºï¼šKaggle - Tourist Review Sentiment Analysis"
)

# --------------------------
# è¼‰å…¥è³‡æ–™
# --------------------------
@st.cache_data
def load_data():
    df = pd.read_csv("merged_data_place.csv")
    if df['review_tokens'].dtype == 'O':
        df['review_tokens'] = df['review_tokens'].apply(eval)
    return df

df = load_data()

# --------------------------
# å´é‚Šæ¬„ç¯©é¸
# --------------------------
places = df['place'].unique().tolist()
selected_place = st.sidebar.multiselect("å„é»ç¶œè¦½", options=places, default=places[:10])

# éæ¿¾è³‡æ–™
df_filtered = df[df['place'].isin(selected_place)]

# --------------------------
# è¨ˆç®—æƒ…ç·’åˆ†å¸ƒèˆ‡é—œéµå­—
# --------------------------
emotion_counts = df_filtered.groupby(['place', 'sentiment']).size().unstack(fill_value=0)
emotion_counts['total_reviews'] = emotion_counts.sum(axis=1)
emotion_counts.reset_index(inplace=True)

place_info = df_filtered[['place','lat','lng']].drop_duplicates(subset=['place'])
emotion_map = pd.merge(emotion_counts, place_info, on='place', how='left')

top_keywords = {}
for place, group_place in df_filtered.groupby("place"):
    top_keywords[place] = {}
    for sentiment, group_sent in group_place.groupby("sentiment"):
        tokens = sum(group_sent['review_tokens'], [])
        count = Counter(tokens)
        top = [word for word, freq in count.most_common(5)]
        top_keywords[place][sentiment] = ", ".join(top)

keywords_df = pd.DataFrame([
    {"place": place, "sentiment": sentiment, "keywords": kws}
    for place, s_dict in top_keywords.items()
    for sentiment, kws in s_dict.items()
])
keyword_pivot = keywords_df.pivot(index='place', columns='sentiment', values='keywords').reset_index()
emotion_map = pd.merge(emotion_map, keyword_pivot, on='place', how='left')

emotion_map = emotion_map.rename(columns={
    'positive_x':'positive',
    'neutral_x':'neutral',
    'negative_x':'negative',
    'positive_y':'positive_keywords',
    'neutral_y':'neutral_keywords',
    'negative_y':'negative_keywords'
})
emotion_map['positive_ratio'] = emotion_map.get('positive', 0) / emotion_map['total_reviews']

# --------------------------
# æ™ºæ…§æ‘˜è¦å‡½å¼
# --------------------------
def generate_recommendation(df, place):
    places = place if isinstance(place, list) else [place]
    results = {}
    for p in places:
        subset = df[df['place'] == p]
        if subset.empty:
            results[p] = f"{p}ï¼šç„¡è³‡æ–™å¯ç”¨ã€‚"
            continue
        pos_ratio = (subset['sentiment'] == 'positive').mean()
        kw_candidates = None
        for col in ['keywords_cn','keywords','review_tokens']:
            if col in subset.columns:
                exploded = subset[col].explode().dropna()
                if not exploded.empty:
                    flat = []
                    for v in exploded:
                        if isinstance(v,list):
                            flat.extend(v)
                        else:
                            flat.append(v)
                    if len(flat)>0:
                        from collections import Counter
                        topk = [x for x,_ in Counter(flat).most_common(3)]
                        kw_candidates = topk
                        break
        if not kw_candidates:
            kw_candidates = []
        if pos_ratio > 0.91:
            mood = "å¼·çƒˆæ¨è–¦ ğŸ‘"
        elif pos_ratio > 0.88:
            mood = "å€¼å¾—ä¸€éŠ ğŸ˜‰"
        elif pos_ratio > 0.85:
            mood = "å¯å®‰æ’çŸ­æš«é€ è¨ªï¼ˆè¦–åå¥½ï¼‰ğŸ¤"
        else:
            mood = "å£ç¢‘æ™®é€šï¼Œå»ºè­°æ–Ÿé…Œæˆ–æŸ¥æ›´å¤šè³‡è¨Š ğŸ¤”"
        kw_str = ", ".join(kw_candidates) if kw_candidates else "ç„¡é¡¯è‘—é—œéµå­—"
        results[p] = f"è©•è«–æ­£å‘æ¯”ä¾‹ç‚º {pos_ratio:.0%}ï¼›ç†±é–€é—œéµå­—ï¼š{kw_str}ã€‚å»ºè­°ï¼š{mood}"
    return results[places[0]] if isinstance(place,str) else results

# ===========================
# ä½¿ç”¨ Tabs å€åˆ† Overview èˆ‡ Detail
# ===========================
tab_overview, tab_detail = st.tabs([" ğŸ‘‰  å¤šæ™¯é»ç¶œè¦½", " ğŸ‘‰  å–®æ™¯é»è©³æƒ…"])

# --------------------------
# Overview - å¤šé¸æ™¯é»
# --------------------------
with tab_overview:
    st.write("#### ğŸ—ºï¸ å¤šæ™¯é»ç¶œè¦½")
    st.write("çµ±è¨ˆæ‘˜è¦ï¼š")
    positive_reviews = df_filtered[df_filtered['sentiment']=='positive'].shape[0]
    st.write(
    f"é¸æ“‡æ™¯é» {df_filtered['place'].nunique()} ç­†ï¼Œ"
    f"åˆè¨ˆè©•è«– {df_filtered.shape[0]} ç­†ï¼Œ"
    f"å¥½è©•æ¯”ä¾‹: {positive_reviews / df_filtered.shape[0]:.2%}"
    )
    
    st.write("##### ğŸ“Š æƒ…ç·’çµ±è¨ˆè¡¨")
    st.dataframe(emotion_map[[
        'place','total_reviews','positive','neutral','negative',
        'positive_keywords','neutral_keywords','negative_keywords'
    ]].sort_values('total_reviews', ascending=False))
    
    st.write("##### ğŸŒ æƒ…ç·’æ°£æ³¡åœ–")
    fig_map = px.scatter_mapbox(
        emotion_map,
        lat="lat",
        lon="lng",
        size="total_reviews",
        color="positive_ratio",
        hover_name="place",
        hover_data=[
            "positive","neutral","negative",
            "positive_keywords","neutral_keywords","negative_keywords"
        ],
        color_continuous_scale=px.colors.diverging.RdYlGn,
        size_max=40,
        zoom=5,
        mapbox_style="carto-positron"
    )
    st.plotly_chart(fig_map, use_container_width=True)

    # å¤šé¸æ™¯é»æ™ºæ…§æ‘˜è¦
    if selected_place:
        suggestion = generate_recommendation(df, selected_place)
        st.write("##### ğŸ¯ æ™ºæ…§æ‘˜è¦")
        if isinstance(suggestion, dict):
            for place, text in suggestion.items():
                st.markdown(f"**{place}**: {text}")
        else:
            st.markdown(suggestion)

# --------------------------
# Detail - å–®æ™¯é»æ·±åº¦åˆ†æ
# --------------------------
with tab_detail:
    st.write("#### ğŸ—ºï¸ å–®æ™¯é»è©³æƒ…")
    selected_detail_place = st.selectbox("é¸æ“‡æ™¯é»æŸ¥çœ‹è©³ç´°è³‡è¨Š", df_filtered['place'].unique())

    # --------------------------
    # ä¸ŠåŠéƒ¨ï¼šä¸‰å¼µåœ–æ°´å¹³æ’åˆ—
    # --------------------------
    col1, col2, col3 = st.columns([1,1,1])
    CHART_HEIGHT = 400  # çµ±ä¸€é«˜åº¦

    # ğŸ“¡ ç‰¹è‰²é›·é”åœ–
    with col1:
        st.write("##### ğŸ“¡ ç‰¹è‰²é›·é”åœ–")
        aspects = {
            "è‡ªç„¶æ™¯è§€": ["lake","lakeside","boating","view","pokhara","annapurna","everest"],
            "å®—æ•™æ–‡åŒ–": ["temple","buddha","lord","shiva","pashupatinath","gautam","stupa","heritage"],
            "æ­·å²å»ºç¯‰": ["square","durbar","historical","bhaktapur","kathmandu","valley"],
            "é‡ç”Ÿå‹•ç‰©èˆ‡è‡ªç„¶å…¬åœ’": ["park","national","safari","animals","chitwan","bardiya","jungle"],
            "æˆ¶å¤–æ¢éšª": ["trekking","trek","camp","experience","base","langtang","icefall","ebc"]
        }

        def aspect_scores(subset):
            scores = {}
            for aspect, kws in aspects.items():
                mask = subset["review_tokens"].apply(lambda tokens: any(kw in tokens for kw in kws))
                scores[aspect] = (subset[mask]["sentiment"]=="positive").mean() if mask.sum()>0 else 0
            return scores

        subset = df[df["place"]==selected_detail_place]
        scores = aspect_scores(subset)
        fig_radar = go.Figure()
        fig_radar.add_trace(go.Scatterpolar(r=list(scores.values()), theta=list(scores.keys()),
                                            fill='toself', name=selected_detail_place))
        fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,1])), showlegend=False,
        height=CHART_HEIGHT)
        st.plotly_chart(fig_radar, use_container_width=True)

    # ğŸ“– ç†±é–€é—œéµå­—
    with col2:
        st.write("##### ğŸ“– ç†±é–€é—œéµå­—")
        tokens = [token for token in df[df['place']==selected_detail_place]['review_tokens'].sum()]
        counter = Counter(tokens)
        top_words = counter.most_common(10)
        words, counts = zip(*top_words)

        fig_keywords = px.bar(
            x=counts,
            y=words,
            orientation='h',
            text=counts,
            labels={'x':'counts','y':'ç†±é–€é—œéµå­—'},
            title=f"{selected_detail_place} - Top 10 Keywords",
            color=counts,
            color_continuous_scale=px.colors.diverging.RdYlGn,
            height=CHART_HEIGHT
        )
        fig_keywords.update_layout(yaxis={'categoryorder':'total ascending'},
                                coloraxis_colorbar=dict(title='counts'))
        st.plotly_chart(fig_keywords, use_container_width=True)

    # â˜ï¸ é—œéµæ–‡å­—é›²
    with col3:
        st.write("##### â˜ï¸ é—œéµæ–‡å­—é›²")
        wordcloud = WordCloud(width=400, height=400, background_color='white').generate(" ".join(tokens))
        fig_wc, ax_wc = plt.subplots(figsize=(6, CHART_HEIGHT/100*6))  # è½‰æˆ inches
        ax_wc.imshow(wordcloud, interpolation='bilinear')
        ax_wc.axis("off")
        st.pyplot(fig_wc)

    # --------------------------
    # ä¸‹åŠéƒ¨ï¼šæ™ºæ…§æ‘˜è¦ + PDFä¸‹è¼‰
    # --------------------------
    st.write("##### ğŸ¯ æ™ºæ…§æ‘˜è¦")
    suggestion = generate_recommendation(df, selected_detail_place)
    st.markdown(suggestion)
    
import streamlit as st
import io
import matplotlib.pyplot as plt
from fpdf import FPDF
from wordcloud import WordCloud
from PIL import Image
from fpdf import FPDF

pdf = FPDF(orientation="L", format="A4")
# è¨»å†Šæ”¯æ´ä¸­æ–‡çš„å­—å‹ï¼ŒNotoSansTC-Regular.otf éœ€æ”¾åœ¨ç¨‹å¼å¯è®€å–è·¯å¾‘
pdf.add_font("NotoSans", "", "NotoSansTC-Regular.otf", uni=True)
pdf.add_page()
pdf.set_font("NotoSans", "", 14)

# ä¸­æ–‡/ç‰¹æ®Šå­—å…ƒéƒ½å¯ä»¥äº†
pdf.multi_cell(0, 10, f"â˜… Mario äº’å‹•é­”æ³•é¡å ±å‘Š ({selected_place})", align="C")
pdf.multi_cell(0, 8, f"æ™ºæ…§æ‘˜è¦ï¼š{suggestion}")

# ---------- å¹«åŠ©å‡½å¼ï¼šç”¨ matplotlib ç•«åœ–ï¼Œå­˜æª” ----------
def save_figure_matplotlib(fig_func, out_path, *args, **kwargs):
    """
    fig_func: ä¸€å€‹å‡½æ•¸ï¼Œå›å‚³ matplotlib.figure.Figure
    out_path: PNG è¼¸å‡ºè·¯å¾‘
    args, kwargs: å‚³çµ¦ fig_func
    """
    try:
        fig = fig_func(*args, **kwargs)
        fig.savefig(out_path, bbox_inches="tight")
        plt.close(fig)
    except Exception as e:
        # å¤±æ•—æ™‚ç”¢ç”Ÿ placeholder
        W, H = 1200, 800
        img = Image.new("RGB", (W, H), color="white")
        from PIL import ImageDraw, ImageFont
        draw = ImageDraw.Draw(img)
        msg = ["Figure generation failed", f"Error: {type(e).__name__}"]
        try:
            font = ImageFont.load_default()
        except:
            font = None
        y = 40
        for line in msg:
            draw.text((40, y), line, fill="black", font=font)
            y += 28
        img.save(out_path)

# ---------- ç”¢ç”Ÿ PDF ----------
def generate_pdf(selected_place, suggestion, radar_scores, keywords_counts, keywords_words, tokens, map_df):
    import os, tempfile

    with tempfile.TemporaryDirectory() as tmpdir:
        # åœ–ç‰‡è·¯å¾‘
        radar_path = os.path.join(tmpdir, "radar.png")
        bar_path   = os.path.join(tmpdir, "bar.png")
        wc_path    = os.path.join(tmpdir, "wc.png")
        map_path   = os.path.join(tmpdir, "map.png")

        # 1ï¸âƒ£ Radar chart
        def radar_fig(scores):
            import numpy as np
            categories = list(scores.keys())
            values = list(scores.values())
            N = len(categories)
            angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()
            values += values[:1]
            angles += angles[:1]
            fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(polar=True))
            ax.plot(angles, values, 'o-', linewidth=2)
            ax.fill(angles, values, alpha=0.25)
            ax.set_thetagrids(np.degrees(angles[:-1]), categories)
            ax.set_ylim(0,1)
            return fig
        save_figure_matplotlib(radar_fig, radar_path, radar_scores)

        # 2ï¸âƒ£ Bar chart
        def bar_fig(words, counts):
            fig, ax = plt.subplots(figsize=(6,6))
            ax.barh(words, counts, color="green")
            ax.set_xlabel("Counts")
            ax.set_ylabel("Keywords")
            ax.invert_yaxis()
            return fig
        save_figure_matplotlib(bar_fig, bar_path, keywords_words, keywords_counts)

        # 3ï¸âƒ£ WordCloud
        wc = WordCloud(width=400, height=400, background_color="white").generate(" ".join(tokens))
        fig_wc, ax_wc = plt.subplots(figsize=(6,6))
        ax_wc.imshow(wc, interpolation="bilinear")
        ax_wc.axis("off")
        fig_wc.savefig(wc_path, bbox_inches="tight")
        plt.close(fig_wc)

        # 4ï¸âƒ£ Map placeholder (å› ç‚º scatter_mapbox åªèƒ½ Streamlit é¡¯ç¤ºï¼Œé€™è£¡ç•«ç°¡å–®é»)
        fig_map, ax_map = plt.subplots(figsize=(6,6))
        ax_map.text(0.5,0.5,"æƒ…ç·’æ°£æ³¡åœ–\n(ä¸‹è¼‰ PDF é¡¯ç¤º placeholder)", ha="center", va="center")
        ax_map.axis("off")
        fig_map.savefig(map_path, bbox_inches="tight")
        plt.close(fig_map)

        # ---------- å»ºç«‹ PDF ----------
        pdf = FPDF(orientation="L", format="A4")
        pdf.add_page()
        pdf.set_font("Arial", "", 14)

        # æ¨™é¡Œ
        pdf.multi_cell(0, 10, f"â˜… Mario äº’å‹•é­”æ³•é¡å ±å‘Š ({selected_place})", align="C")
        pdf.ln(5)
        pdf.set_font("Arial", "", 12)
        pdf.multi_cell(0, 8, f"æ™ºæ…§æ‘˜è¦ï¼š{suggestion}")
        pdf.ln(5)

        # å››åœ– 2x2
        img_h = 70
        margin_x, start_y = 15, pdf.get_y()+5
        gap_x, gap_y = 15, 12

        for i, (title, path) in enumerate([("â˜… ç‰¹è‰²é›·é”åœ–", radar_path), ("â˜… ç†±é–€é—œéµå­—", bar_path)]):
            x = margin_x + i*(img_h + gap_x)
            pdf.set_xy(x, start_y-6)
            pdf.multi_cell(img_h,6,title)
            pdf.image(path,x=x,y=start_y,w=img_h,h=img_h)

        second_row_y = start_y + img_h + gap_y
        for i, (title,path) in enumerate([("â˜… é—œéµæ–‡å­—é›²", wc_path), ("â˜… æƒ…ç·’æ°£æ³¡åœ–", map_path)]):
            x = margin_x + i*(img_h + gap_x)
            pdf.set_xy(x, second_row_y-6)
            pdf.multi_cell(img_h,6,title)
            pdf.image(path,x=x,y=second_row_y,w=img_h,h=img_h)

        # åŒ¯å‡º PDF åˆ° bytes
        pdf_bytes = io.BytesIO()
        pdf.output(pdf_bytes)
        pdf_bytes.seek(0)
        return pdf_bytes.read()


# ---------- Streamlit ä¸‹è¼‰æŒ‰éˆ• ----------
if st.button("ğŸ“‘ ä¸‹è¼‰ PDF"):
    pdf_data = generate_pdf(
        selected_place=selected_detail_place,
        suggestion=suggestion,
        radar_scores=scores,
        keywords_counts=[count for count in counter.values()],
        keywords_words=[word for word in counter.keys()],
        tokens=tokens,
        map_df=None
    )
    st.download_button(
        "é»æ­¤ä¸‹è¼‰å®Œæ•´ PDF å ±å‘Š",
        data=pdf_data,
        file_name="report.pdf",
        mime="application/pdf"
    )





















